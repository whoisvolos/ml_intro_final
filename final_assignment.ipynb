{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Финальное задание курса \"Введение в машинное обучение\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузим все необходимые модули\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузим обучающую выборку в датафрейм пандасов\n",
    "data = pd.read_csv(\"data/features.csv\", index_col=\"match_id\")\n",
    "data_size = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Удалим признаки, определенные для конца матча\n",
    "future_features = [\n",
    "    'tower_status_radiant',\n",
    "    'tower_status_dire',\n",
    "    'barracks_status_radiant',\n",
    "    'barracks_status_dire',\n",
    "    'duration'\n",
    "]\n",
    "data.drop(future_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_time: 19553 NaNs\n",
      "first_blood_team: 19553 NaNs\n",
      "first_blood_player1: 19553 NaNs\n",
      "first_blood_player2: 43987 NaNs\n",
      "radiant_bottle_time: 15691 NaNs\n",
      "radiant_courier_time: 692 NaNs\n",
      "radiant_flying_courier_time: 27479 NaNs\n",
      "radiant_first_ward_time: 1836 NaNs\n",
      "dire_bottle_time: 16143 NaNs\n",
      "dire_courier_time: 676 NaNs\n",
      "dire_flying_courier_time: 26098 NaNs\n",
      "dire_first_ward_time: 1826 NaNs\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим где есть пропуски\n",
    "nan_columns = [c for c in data.columns if data[c].count() < data_size]\n",
    "for c in nan_columns:\n",
    "    print \"{c}: {n} NaNs\".format(c=c, n=(data_size - data[c].count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и было сказано в документации, все пропуски имеют значения - не поставили варды или не купили бутылку, не убили героя до 5 минут матча. Не хотелось бы так \"в лоб\" заполнять все нулями (ноль имеет значение - это начало матча). Посмотрим какие диапазоны принимают данные фичи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_time: min: -78.0, max: 300.0\n",
      "first_blood_team: min: 0.0, max: 1.0\n",
      "first_blood_player1: min: 0.0, max: 9.0\n",
      "first_blood_player2: min: 0.0, max: 9.0\n",
      "radiant_bottle_time: min: -37.0, max: 300.0\n",
      "radiant_courier_time: min: -90.0, max: 300.0\n",
      "radiant_flying_courier_time: min: 180.0, max: 300.0\n",
      "radiant_first_ward_time: min: -236.0, max: 300.0\n",
      "dire_bottle_time: min: -45.0, max: 300.0\n",
      "dire_courier_time: min: -90.0, max: 296.0\n",
      "dire_flying_courier_time: min: 180.0, max: 300.0\n",
      "dire_first_ward_time: min: -84.0, max: 300.0\n"
     ]
    }
   ],
   "source": [
    "for c in nan_columns:\n",
    "    print \"{c}: min: {min}, max: {max}\".format(\n",
    "        c=c,\n",
    "        min=data[c].min(),\n",
    "        max=data[c].max()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С номером команды и героями, участвующими в событии 'first_blood' все ясно. Остальные фичи (кроме 'radiant_first_ward_time' - у него как видим есть выброс в минимуме) принимают значение от -90 (время стартует за полторы минуты до начала матча) до 300 - 5 минут в секундах. Заполним пропущенные значения на малое значение, а также пофиксим выброс (тоже малым значением)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.fillna(value=-10000.0, inplace=True, axis=1)\n",
    "data.loc[data['radiant_first_ward_time'] < -90.0, 'radiant_first_ward_time'] = -10000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_time: 0 NaNs, min: -10000.0, max: 300.0\n",
      "first_blood_team: 0 NaNs, min: -10000.0, max: 1.0\n",
      "first_blood_player1: 0 NaNs, min: -10000.0, max: 9.0\n",
      "first_blood_player2: 0 NaNs, min: -10000.0, max: 9.0\n",
      "radiant_bottle_time: 0 NaNs, min: -10000.0, max: 300.0\n",
      "radiant_courier_time: 0 NaNs, min: -10000.0, max: 300.0\n",
      "radiant_flying_courier_time: 0 NaNs, min: -10000.0, max: 300.0\n",
      "radiant_first_ward_time: 0 NaNs, min: -10000.0, max: 300.0\n",
      "dire_bottle_time: 0 NaNs, min: -10000.0, max: 300.0\n",
      "dire_courier_time: 0 NaNs, min: -10000.0, max: 296.0\n",
      "dire_flying_courier_time: 0 NaNs, min: -10000.0, max: 300.0\n",
      "dire_first_ward_time: 0 NaNs, min: -10000.0, max: 300.0\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим, остались ли пропуски и какие диапазоны у нас теперь\n",
    "for c in nan_columns:\n",
    "    print \"{c}: {n} NaNs, min: {min}, max: {max}\".format(\n",
    "        c=c,\n",
    "        n=(data_size - data[c].count()),\n",
    "        min=data[c].min(),\n",
    "        max=data[c].max()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Выделим целевую переменную и удалим ее из датасета\n",
    "y = data['radiant_win']\n",
    "data.drop(['radiant_win'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный бустинг в лоб\n",
    "Отлично, данные подготовлены, можно запустить бустинг, проверить качество по метрике ROC AUC и попытаться найти оптимум по параметру n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Создадим разбиение для кросс-валидации\n",
    "n_folds = 5\n",
    "cv = KFold(n=data_size, n_folds=n_folds, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting and calculating quality metric for n=10\n",
      "Final ROC AUC for 10=0.664363197162, took: 10.4882885933 second(s)\n",
      "Fitting and calculating quality metric for n=20\n",
      "Final ROC AUC for 20=0.681674512259, took: 19.5691465855 second(s)\n",
      "Fitting and calculating quality metric for n=30\n",
      "Final ROC AUC for 30=0.689084320614, took: 29.317814064 second(s)\n",
      "Fitting and calculating quality metric for n=100\n",
      "Final ROC AUC for 100=0.70597260216, took: 103.34880228 second(s)\n",
      "Fitting and calculating quality metric for n=200\n",
      "Final ROC AUC for 200=0.713664080503, took: 204.339993763 second(s)\n"
     ]
    }
   ],
   "source": [
    "for n_estim in [10, 20, 30, 100, 200]:\n",
    "    auc_mean = 0.0\n",
    "    times = 0.0\n",
    "    # Будем оценивать кросс-валидацию напрямую, безо всяких GridSearchCV, чтобы показать как это считается\n",
    "    print \"Fitting and calculating quality metric for n={n}\".format(n=n_estim)\n",
    "    for train_idx, test_idx in cv:\n",
    "        # Создадим классификатор\n",
    "        clf = GradientBoostingClassifier(n_estimators=n_estim)\n",
    "        cur_time = time.time()\n",
    "        # Обучим на 4/5 от трейн-сета, выбранных кросс-валидацией\n",
    "        clf.fit(data.iloc[train_idx], y.iloc[train_idx])\n",
    "        times += (time.time() - cur_time)\n",
    "        # Получим предсказания для 1/5 трейн-сета\n",
    "        y_pred = clf.predict_proba(data.iloc[test_idx])[:, 1]\n",
    "        # Посчитаем метрику\n",
    "        score = roc_auc_score(y.iloc[test_idx], y_pred)\n",
    "        auc_mean += score\n",
    "    # Посчитаем среднее для метрики по 5 фолдам, а также среднее затраченного времени    \n",
    "    auc_mean = auc_mean / float(n_folds)\n",
    "    times = times / float(n_folds)\n",
    "    print \"Final ROC AUC for {n} = {r}, avg. time: {sec} second(s)\".format(n=n_estim, r=auc_mean, sec=times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "Все считалось в 1 поток на ноутбучном i5. Видно, что для n = 10 было затрачено около 10 сек, для n = 20 около 20 сек, для 30 - 30 сек, для 100 - 100 и т.д, то есть время работы алгоритма линейно от носительно параметра n_estimators. Так же видно, что оптимум не достигнут не то, что на n = 30, но даже и на n = 100 (он точно продолжит расти и дальше - я пробовал, хотя очень нелинейно относительно n_estimators).\n",
    "\n",
    "Значение метрики качества на бустинге для 30 деревьев: **0.68908**.\n",
    "\n",
    "Как сделать быстрее:\n",
    "    - Поиграть параметрами модели, использовать меньше деревьев, уменьшить глубину деревьев или learning_rate - это может ухудшить качество.\n",
    "    \n",
    "    - Обучаться на меньшем кол-ве данных или признаков.\n",
    "    \n",
    "    - Распараллелиться на всех ядрах машины. Тут поможет GridSearchCV (или другие методы или библиотеки поиска гиперпараметров) или библиотека joblib (gridsearch использует ее внутри). Таким образом, каждый прогон каждого разбиения кросс-валидации будет считаться параллельно, если хватит ядер. GridSearchCV довольно глючный, иногда отказывается работать по странным причинам (вроде комментариев на русском языке) и по стек-трейсу ошибки на пяток экранов не всегда можно понять в чем дело. Можно воспользоваться библиотеками или алгоритмами, которые умеют параллелиться автоматически: xgboost библиотека умеет параллелиться сама, RandomForestClassifier из sklearn параллелится с помощью параметра n_jobs.\n",
    "    \n",
    "    - Распараллелиться на множестве машин. Закладочка \"Clusters\" в IPython ноутбуках, кастомные решения, например с помощью библиотеки Celery. Или для джедаев Spark + MlLib на хадуп-кластерах. Под спарк есть питон-расширение pyspark, а так же с помощью SparkQL можно работать с данными в стиле Pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия\n",
    "Для нее мы немного по-другому приготовим данные. Они будут готовиться почти так же, как и для бустинга, но вместо малых значений для пропусков я буду использовать средние значения по признаку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Заново прочтем данные\n",
    "data = pd.read_csv(\"data/features.csv\", index_col=\"match_id\")\n",
    "data_size = data.shape[0]\n",
    "data.drop(future_features, axis=1, inplace=True)\n",
    "\n",
    "# Усредним пропуски с учетом колонки с выбросом\n",
    "data.loc[data['radiant_first_ward_time'] < -90.0, 'radiant_first_ward_time'] = \\\n",
    "    data[data['radiant_first_ward_time'] >= -90.0]['radiant_first_ward_time'].mean()\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Выделим целевую переменную и удалим ее из датасета\n",
    "y = data['radiant_win']\n",
    "data.drop(['radiant_win'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting and calculating quality metric for C=1e-06\n",
      "Final ROC AUC for 1e-06 = 0.513446070187, avg. time: 0.40812458992 second(s)\n",
      "Fitting and calculating quality metric for C=1e-05\n",
      "Final ROC AUC for 1e-05 = 0.513446070187, avg. time: 0.418340158463 second(s)\n",
      "Fitting and calculating quality metric for C=0.0001\n",
      "Final ROC AUC for 0.0001 = 0.513446070187, avg. time: 0.409064531326 second(s)\n",
      "Fitting and calculating quality metric for C=0.001\n",
      "Final ROC AUC for 0.001 = 0.513446070187, avg. time: 0.498295354843 second(s)\n",
      "Fitting and calculating quality metric for C=0.01\n",
      "Final ROC AUC for 0.01 = 0.513446070187, avg. time: 0.538801956177 second(s)\n",
      "Fitting and calculating quality metric for C=0.1\n",
      "Final ROC AUC for 0.1 = 0.513446070187, avg. time: 0.408539295197 second(s)\n",
      "Fitting and calculating quality metric for C=1.0\n",
      "Final ROC AUC for 1.0 = 0.513446070187, avg. time: 0.443279266357 second(s)\n",
      "Fitting and calculating quality metric for C=10.0\n",
      "Final ROC AUC for 10.0 = 0.513446070187, avg. time: 0.399044752121 second(s)\n"
     ]
    }
   ],
   "source": [
    "# Обучим сначала как есть (подберем оптимальное значение параметра L2-регуляризации)\n",
    "for C in np.logspace(-6, 1, 8):\n",
    "    auc_mean = 0.0\n",
    "    times = 0.0\n",
    "    print \"Fitting and calculating quality metric for C={c}\".format(c=C)\n",
    "    for train_idx, test_idx in cv:\n",
    "        clf = LogisticRegression(penalty='l2', C=C)\n",
    "        cur_time = time.time()\n",
    "        clf.fit(data.iloc[train_idx], y.iloc[train_idx])\n",
    "        times += (time.time() - cur_time)\n",
    "        y_pred = clf.predict_proba(data.iloc[test_idx])[:, 1]\n",
    "        score = roc_auc_score(y.iloc[test_idx], y_pred)\n",
    "        auc_mean += score\n",
    "    auc_mean = auc_mean / float(n_folds)\n",
    "    times = times / float(n_folds)\n",
    "    print \"Final ROC AUC for {c} = {r}, avg. time: {sec} second(s)\".format(c=C, r=auc_mean, sec=times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мда, качество получилось как у тривиального классификатора, дающего в кач-ве ответа всегда 0. Дело в том, что выборки линейно не разделимы, категориальные фичи классификатор использует как числовые, а масштабы фич существенно различаются. Попробуем убрать категориальные фичи (да, вообще), а оставшиеся поскейлить. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 112)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Для начала посчитаем разных героев\n",
    "heroes_columns = []\n",
    "for p in xrange(5):\n",
    "    heroes_columns.append(\"r%d_hero\" % (p + 1))\n",
    "    heroes_columns.append(\"d%d_hero\" % (p + 1))\n",
    "    \n",
    "heroes_unique = np.unique(data[heroes_columns])\n",
    "N_unique_heroes = len(heroes_unique)\n",
    "max_hero_id = heroes_unique.max()\n",
    "N_unique_heroes, max_hero_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что героев всего 112, но в играх присутствуют только 108 из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Сохраним перед удалением bag-of-heroes в отдельной матричке\n",
    "# Код взят из задания\n",
    "X_pick = np.zeros((data_size, max_hero_id))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in xrange(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "# Убираем героев\n",
    "data.drop(heroes_columns, inplace=True, axis=1)\n",
    "\n",
    "# Остальные фичи скейлим\n",
    "data = StandardScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting and calculating quality metric for C=1e-06\n",
      "Final ROC AUC for 1e-06 = 0.685809552789, avg. time: 0.409827947617 second(s)\n",
      "Fitting and calculating quality metric for C=1e-05\n",
      "Final ROC AUC for 1e-05 = 0.694479360768, avg. time: 0.46659784317 second(s)\n",
      "Fitting and calculating quality metric for C=0.0001\n",
      "Final ROC AUC for 0.0001 = 0.712017915524, avg. time: 0.743495559692 second(s)\n",
      "Fitting and calculating quality metric for C=0.001\n",
      "Final ROC AUC for 0.001 = 0.716732742203, avg. time: 1.36488780975 second(s)\n",
      "Fitting and calculating quality metric for C=0.01\n",
      "Final ROC AUC for 0.01 = 0.71688025897, avg. time: 1.92223472595 second(s)\n",
      "Fitting and calculating quality metric for C=0.1\n",
      "Final ROC AUC for 0.1 = 0.716854295076, avg. time: 2.08190789223 second(s)\n",
      "Fitting and calculating quality metric for C=1.0\n",
      "Final ROC AUC for 1.0 = 0.716850357714, avg. time: 1.9373673439 second(s)"
     ]
    }
   ],
   "source": [
    "# Обучим классификатор и посчитаем качество на новом датасете\n",
    "for C in np.logspace(-6, 1, 8):\n",
    "    auc_mean = 0.0\n",
    "    times = 0.0\n",
    "    print \"Fitting and calculating quality metric for C={c}\".format(c=C)\n",
    "    for train_idx, test_idx in cv:\n",
    "        clf = LogisticRegression(penalty='l2', C=C)\n",
    "        cur_time = time.time()\n",
    "        clf.fit(data[train_idx], y.iloc[train_idx])\n",
    "        times += (time.time() - cur_time)\n",
    "        y_pred = clf.predict_proba(data[test_idx])[:, 1]\n",
    "        score = roc_auc_score(y.iloc[test_idx], y_pred)\n",
    "        auc_mean += score\n",
    "    auc_mean = auc_mean / float(n_folds)\n",
    "    times = times / float(n_folds)\n",
    "    print \"Final ROC AUC for {c} = {r}, avg. time: {sec} second(s)\".format(c=C, r=auc_mean, sec=times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Намного лучше! Во-первых, мы переплюнули бустинг и нашли оптимум для параметра регуляризации. Теперь лучший результат по метрике ROC AUC равен **0.71688**. И во-вторых линейная регрессия намного быстрее бустинга. Что же будет, если мы добавим к нашему датасету bag-of-heroes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.hstack((data, X_pick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting and calculating quality metric for C=1e-06\n",
      "Final ROC AUC for 1e-06 = 0.687929876055, avg. time: 0.449196243286 second(s)\n",
      "Fitting and calculating quality metric for C=1e-05\n",
      "Final ROC AUC for 1e-05 = 0.69832496083, avg. time: 0.535328006744 second(s)\n",
      "Fitting and calculating quality metric for C=0.0001\n",
      "Final ROC AUC for 0.0001 = 0.725469529197, avg. time: 0.888973999023 second(s)\n",
      "Fitting and calculating quality metric for C=0.001\n",
      "Final ROC AUC for 0.001 = 0.746206428167, avg. time: 1.85397200584 second(s)\n",
      "Fitting and calculating quality metric for C=0.01\n",
      "Final ROC AUC for 0.01 = 0.7515877894, avg. time: 3.01976079941 second(s)\n",
      "Fitting and calculating quality metric for C=0.1\n",
      "Final ROC AUC for 0.1 = 0.751806638585, avg. time: 4.05457396507 second(s)\n",
      "Fitting and calculating quality metric for C=1.0\n",
      "Final ROC AUC for 1.0 = 0.751787310642, avg. time: 4.20827679634 second(s)\n",
      "Fitting and calculating quality metric for C=10.0\n",
      "Final ROC AUC for 10.0 = 0.751783993432, avg. time: 4.59412231445 second(s)\n"
     ]
    }
   ],
   "source": [
    "# Заново обучим классификатор и посчитаем качество с учетом bag-of-heroes\n",
    "for C in np.logspace(-6, 1, 8):\n",
    "    auc_mean = 0.0\n",
    "    times = 0.0\n",
    "    print \"Fitting and calculating quality metric for C={c}\".format(c=C)\n",
    "    for train_idx, test_idx in cv:\n",
    "        clf = LogisticRegression(penalty='l2', C=C)\n",
    "        cur_time = time.time()\n",
    "        clf.fit(data[train_idx], y.iloc[train_idx])\n",
    "        times += (time.time() - cur_time)\n",
    "        y_pred = clf.predict_proba(data[test_idx])[:, 1]\n",
    "        score = roc_auc_score(y.iloc[test_idx], y_pred)\n",
    "        auc_mean += score\n",
    "    auc_mean = auc_mean / float(n_folds)\n",
    "    times = times / float(n_folds)\n",
    "    print \"Final ROC AUC for {c} = {r}, avg. time: {sec} second(s)\".format(c=C, r=auc_mean, sec=times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель стала еще лучше с добавлением bag-of-heroes! Видимо, добавление этих 112 новых признаков сделал набор данных достаточно линейно разделимым, чтобы получить качество лучше, чем у бустинга. Скорость работы все так же куда больше, чем у бустинга. Итак, новое значение метрики ROC AUC для лучшего алгоритма: **0.75181**. Оптимум по параметру регуляризации так же достижим."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "Бустинг хорошо работает для данной задачи без какой-либо преподготовки данных (кроме убирания пропусков), однако если данные подготовить (преобразовать численные-категориальные фичи в на самом деле категориальные), то логистическая регрессия показывает существенно лучший результат чем бустинг, причем делает это намного быстрее. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Kaggle\n",
    "Сделаем предикшен тестового датасета с использованием лучшего классификатора по метрике ROC AUC - логичестической регрессии с регуляризацией L2 и параметром C = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for fit: 5.034702 seconds\n"
     ]
    }
   ],
   "source": [
    "# Обучим выбранный классификатор на всем трейн-сете\n",
    "clf = LogisticRegression(penalty='l2', C=0.1)\n",
    "times = time.time()\n",
    "clf.fit(data, y)\n",
    "print \"Time taken for fit: %f seconds\" % (time.time() - times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_time: min: -46.0, max: 300.0\n",
      "first_blood_team: min: 0.0, max: 1.0\n",
      "first_blood_player1: min: 0.0, max: 9.0\n",
      "first_blood_player2: min: 0.0, max: 9.0\n",
      "radiant_bottle_time: min: -19.0, max: 300.0\n",
      "radiant_courier_time: min: -90.0, max: 276.0\n",
      "radiant_flying_courier_time: min: 180.0, max: 300.0\n",
      "radiant_first_ward_time: min: -85.0, max: 297.0\n",
      "dire_bottle_time: min: -22.0, max: 300.0\n",
      "dire_courier_time: min: -90.0, max: 291.0\n",
      "dire_flying_courier_time: min: 180.0, max: 300.0\n",
      "dire_first_ward_time: min: -83.0, max: 300.0\n"
     ]
    }
   ],
   "source": [
    "# Прочтем датасет, посмотрим на пропуски и диапазоны\n",
    "data = pd.read_csv(\"data/features_test.csv\", index_col='match_id')\n",
    "data_size = data.shape[0]\n",
    "\n",
    "# Будущих фич тут нет, ничего не удаляем\n",
    "\n",
    "nan_columns = [c for c in data.columns if data[c].count() < data_size]\n",
    "for c in nan_columns:\n",
    "    print \"{c}: min: {min}, max: {max}\".format(\n",
    "        c=c,\n",
    "        min=data[c].min(),\n",
    "        max=data[c].max()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Выбросов нет, просто усредним\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# Сохраним перед удалением bag-of-heroes в отдельной матричке\n",
    "# Код взят из задания\n",
    "X_pick = np.zeros((data_size, max_hero_id))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in xrange(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "# Убираем героев\n",
    "data.drop(heroes_columns, inplace=True, axis=1)\n",
    "\n",
    "# Остальные фичи скейлим\n",
    "data_sc = StandardScaler().fit_transform(data)\n",
    "\n",
    "# Вернем обратно героев\n",
    "data_sc = np.hstack((data_sc, X_pick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Получим предсказанные вероятности класса\n",
    "y_pred = pd.DataFrame(data=clf.predict_proba(data_sc)[:, 1], index=data.index, columns=['radiant_win'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Запишем в csv\n",
    "y_pred.to_csv('data/submission.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_id,radiant_win\r\n",
      "6,0.850643326166\r\n",
      "7,0.746478855938\r\n",
      "10,0.204861783524\r\n",
      "13,0.859376059674\r\n",
      "16,0.244659652357\r\n",
      "18,0.409745211974\r\n",
      "19,0.510930975542\r\n",
      "24,0.559346792983\r\n",
      "33,0.219988610415\r\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим, что записалось\n",
    "! head data/submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично! Отсылаем задание на Кегл и радуемся заслуженному результату ROC AUC **0.75534** и месту **82** (на 12.03.2016 17:24 MSK).\n",
    "![caption](data/kaggle.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
