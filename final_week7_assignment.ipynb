{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def del_future_features(data):\n",
    "    try:\n",
    "        del data['tower_status_radiant']\n",
    "        del data['tower_status_dire']\n",
    "        del data['barracks_status_radiant']\n",
    "        del data['barracks_status_dire']\n",
    "        del data['duration']\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "def get_nan_columns(data):\n",
    "    data_size = data.shape[0]\n",
    "    return [c for c in data.columns if data[c].count() < data_size]\n",
    "\n",
    "def del_categorial(data):\n",
    "    try:\n",
    "        for x in range(1, 6):\n",
    "            del data['r{0}_hero'.format(x)]\n",
    "            del data['d{0}_hero'.format(x)]\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "def get_pick_bof(data):\n",
    "    data_size = data.shape[0]\n",
    "    X_pick = np.zeros(shape=(data_size, 112))\n",
    "    for i, match_id in enumerate(data.index):\n",
    "        for p in xrange(5):\n",
    "            X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "            X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "    return X_pick\n",
    "\n",
    "def scale_features(data):\n",
    "    return StandardScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_for_GBR(file_path):\n",
    "    data = pd.read_csv(file_path, index_col=\"match_id\")\n",
    "\n",
    "    # Remove look-into-future features\n",
    "    del_future_features(data)\n",
    "\n",
    "    # Remove strange lower value for radiant_first_ward_time feature\n",
    "    data = data[(data['radiant_first_ward_time'] >= -90) | (data['radiant_first_ward_time'].isnull())]\n",
    "\n",
    "    # Bag-of-heroes\n",
    "    X_pick = get_pick_bof(data)\n",
    "\n",
    "    # Remove categorial features\n",
    "    del_categorial(data)\n",
    "\n",
    "    # Select target variable\n",
    "    y = data['radiant_win']\n",
    "    del data['radiant_win']\n",
    "\n",
    "    # Convert NaNs to very small value\n",
    "    for c in get_nan_columns(data):\n",
    "        data.loc[(data[c].isnull()), c] = -1000.\n",
    "\n",
    "    # Add converted heroes to train set\n",
    "    data = np.hstack((data, X_pick))\n",
    "    \n",
    "    return data, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_for_LR(file_path):\n",
    "    data = pd.read_csv(file_path, index_col=\"match_id\")\n",
    "\n",
    "    # Remove look-into-future features\n",
    "    del_future_features(data)\n",
    "\n",
    "    # Remove strange lower value for radiant_first_ward_time feature\n",
    "    data = data[(data['radiant_first_ward_time'] >= -90) | (data['radiant_first_ward_time'].isnull())]\n",
    "\n",
    "    # Some deletion\n",
    "    # del data['start_time']\n",
    "    lt = data['lobby_type'].apply(lambda x: -1 if x == 7 else x)\n",
    "    del data['lobby_type']\n",
    "\n",
    "    # Bag-of-heroes\n",
    "    X_pick = get_pick_bof(data)\n",
    "\n",
    "    # Remove categorial features\n",
    "    del_categorial(data)\n",
    "\n",
    "    # Select target variable\n",
    "    y = data['radiant_win']\n",
    "    del data['radiant_win']\n",
    "\n",
    "    # Convert NaNs to means\n",
    "    for c in get_nan_columns(data):\n",
    "        mean = data[c].mean()\n",
    "        data.loc[(data[c].isnull()), c] = mean\n",
    "\n",
    "    # Scale features for LR\n",
    "    data = scale_features(data)\n",
    "\n",
    "    # Add converted heroes to train set\n",
    "    data = np.hstack((data, X_pick))\n",
    "\n",
    "    # Add lobby\n",
    "    # data = np.hstack((data, lt.reshape(lt.shape[0], 1)))\n",
    "    \n",
    "    return data, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, y = data_for_LR(\"data/features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=sklearn.cross_validation.KFold(n=97229, n_folds=5, shuffle=True, random_state=None),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc',\n",
       "       verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_folds = 5\n",
    "cv = KFold(n=data.shape[0], n_folds=n_folds, shuffle=True)\n",
    "grid_params = { 'C': np.logspace(-2, 2, 5) }\n",
    "clf = LogisticRegression(penalty=\"l2\")\n",
    "grid = GridSearchCV(estimator=clf, param_grid=grid_params, scoring='roc_auc', cv=cv, verbose=True, n_jobs=1)\n",
    "grid.fit(data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.75167, std: 0.00149, params: {'C': 0.01},\n",
       " mean: 0.75192, std: 0.00166, params: {'C': 0.10000000000000001},\n",
       " mean: 0.75192, std: 0.00170, params: {'C': 1.0},\n",
       " mean: 0.75192, std: 0.00170, params: {'C': 10.0},\n",
       " mean: 0.75192, std: 0.00170, params: {'C': 100.0}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.752815128275\n",
      "0.749586531267\n",
      "0.749961803829\n",
      "0.75179416175\n",
      "0.756350523377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75210162969948358"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_folds = 5\n",
    "cv = KFold(n=data.shape[0], n_folds=n_folds, shuffle=True)\n",
    "auc_mean = 0.0\n",
    "for train_idx, test_idx in cv:\n",
    "    clf = LogisticRegression(C=0.1, penalty='l2')\n",
    "    clf.fit(data[train_idx], y.iloc[train_idx])\n",
    "    y_pred = clf.predict_proba(data[test_idx])[:, 1]\n",
    "    score = roc_auc_score(y.iloc[test_idx], y_pred)\n",
    "    print score\n",
    "    auc_mean += score\n",
    "auc_mean = auc_mean / float(n_folds)\n",
    "auc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, y = data_for_GBR(\"data/features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3727            3.55m\n",
      "         2           1.3631            3.54m\n",
      "         3           1.3538            3.49m\n",
      "         4           1.3456            3.45m\n",
      "         5           1.3376            3.43m\n",
      "         6           1.3309            3.43m\n",
      "         7           1.3243            3.41m\n",
      "         8           1.3182            3.39m\n",
      "         9           1.3125            3.37m\n",
      "        10           1.3080            3.35m\n",
      "        20           1.2732            3.18m\n",
      "        30           1.2522            3.00m\n",
      "        40           1.2371            2.81m\n",
      "        50           1.2252            2.62m\n",
      "        60           1.2150            2.44m\n",
      "        70           1.2060            2.26m\n",
      "        80           1.1985            2.08m\n",
      "        90           1.1911            1.91m\n",
      "       100           1.1845            1.73m\n",
      "       200           1.1373            0.00s\n",
      "0.736437832312\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3726            3.80m\n",
      "         2           1.3628            3.70m\n",
      "         3           1.3543            3.64m\n",
      "         4           1.3455            3.60m\n",
      "         5           1.3376            3.55m\n",
      "         6           1.3304            3.54m\n",
      "         7           1.3239            3.56m\n",
      "         8           1.3178            3.52m\n",
      "         9           1.3123            3.49m\n",
      "        10           1.3071            3.46m\n",
      "        20           1.2724            3.25m\n",
      "        30           1.2517            3.05m\n",
      "        40           1.2366            2.84m\n",
      "        50           1.2242            2.66m\n",
      "        60           1.2144            2.48m\n",
      "        70           1.2055            2.33m\n",
      "        80           1.1982            2.13m\n",
      "        90           1.1914            1.95m\n",
      "       100           1.1850            1.77m\n",
      "       200           1.1388            0.00s\n",
      "0.733990149088\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3726            3.51m\n",
      "         2           1.3631            3.48m\n",
      "         3           1.3544            3.50m\n",
      "         4           1.3459            3.46m\n",
      "         5           1.3380            3.44m\n",
      "         6           1.3303            3.42m\n",
      "         7           1.3239            3.39m\n",
      "         8           1.3179            3.36m\n",
      "         9           1.3125            3.35m\n",
      "        10           1.3074            3.32m\n",
      "        20           1.2727            3.36m\n",
      "        30           1.2513            3.11m\n",
      "        40           1.2364            2.88m\n",
      "        50           1.2240            2.69m\n",
      "        60           1.2135            2.51m\n",
      "        70           1.2048            2.32m\n",
      "        80           1.1966            2.15m\n",
      "        90           1.1898            1.97m\n",
      "       100           1.1831            1.80m\n",
      "       200           1.1366            0.00s\n",
      "0.734856999065\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3728            3.54m\n",
      "         2           1.3633            3.50m\n",
      "         3           1.3534            3.48m\n",
      "         4           1.3455            3.44m\n",
      "         5           1.3376            3.42m\n",
      "         6           1.3304            3.39m\n",
      "         7           1.3238            3.37m\n",
      "         8           1.3183            3.39m\n",
      "         9           1.3128            3.41m\n",
      "        10           1.3075            3.41m\n",
      "        20           1.2733            3.18m\n",
      "        30           1.2529            3.00m\n",
      "        40           1.2379            2.91m\n",
      "        50           1.2259            2.72m\n",
      "        60           1.2157            2.54m\n",
      "        70           1.2071            2.34m\n",
      "        80           1.1992            2.16m\n",
      "        90           1.1920            1.97m\n",
      "       100           1.1858            1.79m\n",
      "       200           1.1395            0.00s\n",
      "0.741420610084\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3729            3.55m\n",
      "         2           1.3637            3.54m\n",
      "         3           1.3539            3.50m\n",
      "         4           1.3454            3.47m\n",
      "         5           1.3376            3.45m\n",
      "         6           1.3305            3.43m\n",
      "         7           1.3237            3.41m\n",
      "         8           1.3183            3.41m\n",
      "         9           1.3130            3.39m\n",
      "        10           1.3079            3.37m\n",
      "        20           1.2732            3.16m\n",
      "        30           1.2525            3.08m\n",
      "        40           1.2372            2.88m\n",
      "        50           1.2254            2.67m\n",
      "        60           1.2153            2.49m\n",
      "        70           1.2065            2.29m\n",
      "        80           1.1984            2.11m\n",
      "        90           1.1910            1.92m\n",
      "       100           1.1846            1.74m\n",
      "       200           1.1381            0.00s\n",
      "0.737135015221\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73676812115402568"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_folds = 5\n",
    "cv = KFold(n=data.shape[0], n_folds=n_folds, shuffle=True)\n",
    "auc_mean = 0.0\n",
    "for train_idx, test_idx in cv:\n",
    "    clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.2, max_depth=3, verbose=True)\n",
    "    clf.fit(data[train_idx], y.iloc[train_idx])\n",
    "    y_pred = clf.predict_proba(data[test_idx])[:, 1]\n",
    "    score = roc_auc_score(y.iloc[test_idx], y_pred)\n",
    "    print score\n",
    "    auc_mean += score\n",
    "auc_mean = auc_mean / float(n_folds)\n",
    "auc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:   59.4s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done 1000 out of 1000 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715528614343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    6.2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-219f359fc14b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtraTreesClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 290\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m                 \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0;31m# Stop dispatching any new job in the async callback thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "n_folds = 5\n",
    "cv = KFold(n=data.shape[0], n_folds=n_folds, shuffle=True)\n",
    "auc_mean = 0.0\n",
    "for train_idx, test_idx in cv:\n",
    "    clf = ExtraTreesClassifier(n_estimators=1000, verbose=True, n_jobs=4)\n",
    "    clf.fit(data[train_idx], y.iloc[train_idx])\n",
    "    y_pred = clf.predict_proba(data[test_idx])[:, 1]\n",
    "    score = roc_auc_score(y.iloc[test_idx], y_pred)\n",
    "    print score\n",
    "    auc_mean += score\n",
    "auc_mean = auc_mean / float(n_folds)\n",
    "auc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
